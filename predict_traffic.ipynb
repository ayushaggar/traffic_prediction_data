{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import necessary libraries\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from datetime import date\n",
        "\n",
        "# holiday feature\n",
        "\n",
        "\n",
        "def modify_holiday(x):\n",
        "    if x == 'None':\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "# rain feature\n",
        "\n",
        "\n",
        "def modify_rain_1h(x):\n",
        "    if x == 0:\n",
        "        return 'no_rain'\n",
        "    elif x > 0 and x < 100:\n",
        "        return 'light'\n",
        "    elif x > 100 and x < 1000:\n",
        "        return 'moderate'\n",
        "    elif x > 1000:\n",
        "        return 'heavy'\n",
        "\n",
        "# snow feature\n",
        "\n",
        "\n",
        "def modify_snow_1h(x):\n",
        "    if x == 0:\n",
        "        return 'no_snow'\n",
        "    else:\n",
        "        return 'snow'\n",
        "\n",
        "# Feature engineering and Data cleaning\n",
        "\n",
        "\n",
        "def preprocessing(df):\n",
        "\n",
        "    # convert kelvin to celsius\n",
        "    df['temp'] = (df['temp'] - 273.15)\n",
        "\n",
        "    # Outlier in temp and rain which was detected earlier needs to be removed\n",
        "    df = df.loc[df.temp > -240]\n",
        "    df = df.loc[df.rain_1h < 3800]\n",
        "\n",
        "    # Extracting features from date_time variable\n",
        "    df['date_time'] = pd.to_datetime(df.date_time)\n",
        "    df['hour'] = df.date_time.dt.hour\n",
        "    df['month'] = df.date_time.dt.month\n",
        "    df['year'] = df.date_time.dt.year\n",
        "    df['weekday'] = df.date_time.dt.weekday  # Monday is 0\n",
        "    df['date'] = df.date_time.dt.date\n",
        "\n",
        "    # categorizing holiday as True and not Holiday as False\n",
        "    df['holiday'] = df['holiday'].map(\n",
        "        modify_holiday)\n",
        "\n",
        "    # categorizing Rain as no rain, linght, moderate and heavy\n",
        "    df['rain_1h'] = df['rain_1h'].map(\n",
        "        modify_rain_1h)\n",
        "\n",
        "    # categorizing Snow as no snow and not snow\n",
        "    df['snow_1h'] = df['snow_1h'].map(\n",
        "        modify_snow_1h)\n",
        "\n",
        "    # encoding weather information as label 0,1,2,3...\n",
        "    le = LabelEncoder()\n",
        "    df['weather_main'] = le.fit_transform(\n",
        "        df['weather_main'])\n",
        "    df['weather_description'] = le.fit_transform(\n",
        "        df['weather_description'])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def exploratory_analyis(df):\n",
        "\n",
        "    # check if null values - here no null values\n",
        "    print(df.info())\n",
        "\n",
        "    # check outlier and other details - here can find temp(min) and\n",
        "    # rain_1h(max) has outlier\n",
        "    print(df.describe())\n",
        "    print(df.describe(include='object'))\n",
        "    cols = ['clouds_all', 'rain_1h', 'snow_1h', 'temp', 'traffic_volume']\n",
        "    # sns.pairplot(df[cols])\n",
        "    # plt.show()\n",
        "\n",
        "    # correlation between traffic and other variables\n",
        "    # sns.heatmap(df.corr(), annot=True)\n",
        "    # plt.show() # plot show no correlation\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def data_preprocessor():\n",
        "    cat_vars = [\n",
        "        'weather_description',\n",
        "        'weather_main',\n",
        "        'hour',\n",
        "        'month',\n",
        "        'year',\n",
        "        'weekday',\n",
        "        'holiday',\n",
        "        'snow_1h',\n",
        "        'rain_1h']\n",
        "\n",
        "    num_vars = ['temp', 'clouds_all']\n",
        "\n",
        "    # Creating pipeline to transform data\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler())])\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('oneHot', OneHotEncoder())])\n",
        "\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "        ('num', numeric_transformer, num_vars),\n",
        "        ('cat', categorical_transformer, cat_vars)])\n",
        "\n",
        "    return preprocessor\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Import dataset - csv to dataframe\n",
        "    df_traffic_data = pd.read_csv('data/Metro_Interstate_Traffic_Volume.csv')\n",
        "    df_traffic_data = exploratory_analyis(df_traffic_data)\n",
        "    df_traffic_features = preprocessing(df_traffic_data)\n",
        "\n",
        "    # test-data having the latest 60 days\n",
        "    # split data in traing and test data\n",
        "    # as max date is 2018-09-30 so data is splitted at\n",
        "    data_before = df_traffic_features[(df_traffic_features.date_time < pd.to_datetime(\n",
        "        date(2018, 8, 1)))].reset_index(drop=True)\n",
        "    test_index_start = data_before.shape[0]\n",
        "\n",
        "    df_traffic_features.set_index('date', inplace=True)\n",
        "    df_traffic_transformed = data_preprocessor(\n",
        "    ).fit_transform(df_traffic_features).toarray()\n",
        "\n",
        "    x_train = df_traffic_transformed[:test_index_start]\n",
        "    x_test = df_traffic_transformed[test_index_start:]\n",
        "    y_train = df_traffic_features.traffic_volume[:test_index_start]\n",
        "    y_test = df_traffic_features.traffic_volume[test_index_start:]\n",
        "\n",
        "    model = RandomForestRegressor()\n",
        "\n",
        "    parameter = {\n",
        "        'n_estimators': np.arange(\n",
        "            1, 10), 'max_depth': np.arange(\n",
        "            1, 15)}\n",
        "    grid_search = GridSearchCV(model, parameter, cv=3)\n",
        "    grid_search.fit(x_train, y_train)\n",
        "\n",
        "    print(grid_search.best_params_)\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=grid_search.best_params_['n_estimators'],\n",
        "        max_depth=grid_search.best_params_['max_depth'])\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    pred = model.predict(x_test)\n",
        "    print('R2: ', round(metrics.r2_score(y_test, pred) * 100, 2), '%')\n",
        "    print('Mean Absolute Error: ', metrics.mean_absolute_error(y_test, pred))\n",
        "    print('Root Mean Squared Error: ', np.sqrt(\n",
        "        metrics.mean_squared_error(y_test, pred)))\n",
        "\n",
        "    with open('model/regression_model.pkl', 'wb') as fid:\n",
        "        pickle.dump(model, fid)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}